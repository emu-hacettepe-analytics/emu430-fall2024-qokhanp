[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Our Course Project",
    "section": "",
    "text": "I’m honored to be a member of the [group name] project team.\nBelow, you’ll find a brief summary of our project. To access a detailed project description, please go to EMU430_project_team_NRG.\nSummary\nOur project explores the role of electric vehicles (EVs) in reducing CO2 emissions and assesses their integration within Türkiye. EVs are recognized for their environmental advantages, especially their capacity to lower transportation-related carbon emissions. This study highlights that although adopting EVs can substantially mitigate emissions, its overall success is influenced by factors like population density and the shift toward renewable energy in electricity production.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello, i am Gokhan Polat,\nan Industrial Engineering student with a passion for data analytics, sustainable development, and technology-driven solutions. On this website, i will be sharing my latest projects, insights into data analysis, and much more.\nFeel free to connect and follow along!\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "than 2500 reviews, and save the URLs.\nhttps://m.imdb.com/search/title/?title_type=feature&num_votes=2500,&country_of_origin=TR\nmovies_2010_2023 &lt;- 2010-2023: https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\nmovies_before_2010 &lt;- - 2009: https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\n\n\nCode\nmovies_2010_2023 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\"\n\nmovies_before_2010 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"\n\nurls &lt;- c(movies_2010_2023, movies_before_2010)\n\n# Vektörü görüntüleme\nprint(urls)\n\n\n[1] \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\"\n[2] \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"          \n\n\n\n\n\nRating, Votes\nThe libraries we will need are:\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'ggplot2' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.2\n\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.2\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'stringr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(rvest)\n\n\nWarning: package 'rvest' was built under R version 4.4.2\n\n\n\nAttaching package: 'rvest'\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n\nCode\nlibrary(stringr)\n\n\n\n\nCode\n# Veri çekmek için boş bir liste oluşturun\ndata_list &lt;- list()\n\n# Her URL için veri çekimi\nfor (url in urls) {\n  page &lt;- read_html(url)\n  \n  # Başlıklar\n  titles &lt;- page |&gt;\n    html_nodes('.ipc-title__text') |&gt; \n    html_text() |&gt;\n  tail(-1) |&gt;  # İlk öğeyi kaldır\n  head(-1)\n  \n  # Yıllar ve Süreler\n  metadata &lt;- page |&gt;\n    html_nodes('.sc-300a8231-7.eaXxft.dli-title-metadata-item') |&gt; \n    html_text()\n  \n  years &lt;- metadata |&gt; \n  str_extract(\"^\\\\d{4}$\") |&gt;  # Sadece 4 basamaklı yıl bilgilerini seç\n  as.numeric()  \n  \n  durations &lt;- metadata[seq(2, length(metadata), by = 2)] |&gt; \n    str_replace(\" min\", \"\") |&gt; \n    as.numeric()\n  \n  # Oyların ham verisini kontrol et\nraw_votes &lt;- page |&gt;\n  html_nodes('.ipc-rating-star--voteCount') |&gt; \n  html_text()\n  \n  # Puanlar\n  ratings &lt;- page |&gt;\n    html_nodes('.ipc-rating-star--rating') |&gt; \n    html_text() |&gt; \n    as.numeric()\n  \n  # Oy Sayıları\n  votes &lt;- raw_votes |&gt;\n  str_trim() |&gt;                            # Başındaki ve sonundaki boşlukları kaldır\n  str_replace_all('\"', \"\") |&gt;              # Çift tırnakları kaldır\n  str_replace_all(\"K\", \"e3\") |&gt;            # \"K\"yi bilimsel gösterimle 1000 olarak değiştir\n  str_replace_all(\"k\", \"e3\") |&gt;            # \"k\" için de aynı işlemi yap\n  parse_number()                           # Metni sayıya dönüştür\n\n\n  \n  # Çekilen verileri listeye ekleyin\n  data_list[[url]] &lt;- list(\n    titles = titles,\n    years = years,\n    durations = durations,\n    ratings = ratings,\n    votes = votes\n  )\n}\n\n\nWarning: Zorlamadan dolayı ortaya çıkan NAs\nWarning: Zorlamadan dolayı ortaya çıkan NAs\n\n\nCode\n# Sonuçları kontrol edin\nhead(data_list[[urls[1]]]$votes)\n\n\n[1] 16000 58000 10000  4500 57000 45000\n\n\n\n\nCode\nprint(metadata)\n\n\n [1] \"2009\"      \"2h\"        \"G\"         \"2005\"      \"1h 48m\"    \"G\"        \n [7] \"2004\"      \"2h 7m\"     \"18+\"       \"2007\"      \"1h 32m\"    \"13+\"      \n[13] \"2002\"      \"1h 50m\"    \"18+\"       \"2006\"      \"1h 43m\"    \"18+\"      \n[19] \"1996\"      \"2h 8m\"     \"7+\"        \"1997\"      \"1h 50m\"    \"13+\"      \n[25] \"2007\"      \"2h 20m\"    \"7+\"        \"2008\"      \"1h 53m\"    \"13+\"      \n[31] \"1989\"      \"1h 25m\"    \"1975\"      \"1h 25m\"    \"1982\"      \"1h 47m\"   \n[37] \"PG\"        \"2009\"      \"1h 40m\"    \"7+\"        \"2009\"      \"1h 38m\"   \n[43] \"13+\"       \"2008\"      \"2h 7m\"     \"13+\"       \"2009\"      \"2h 8m\"    \n[49] \"13+\"       \"1997\"      \"2h\"        \"13+\"       \"2008\"      \"1h 49m\"   \n[55] \"Not Rated\" \"2009\"      \"1h 52m\"    \"7+\"        \"1998\"      \"1h 42m\"   \n[61] \"2006\"      \"1h 37m\"    \"Unrated\"   \"2001\"      \"1h 50m\"    \"16+\"      \n[67] \"2008\"      \"1h 30m\"    \"13+\"       \"1977\"      \"1h 30m\"   \n\n\n\n\nCode\nprint(length(titles))    # Başlıklar\n\n\n[1] 25\n\n\nCode\nprint(length(years))     # Yıllar\n\n\n[1] 71\n\n\nCode\nprint(length(durations)) # Süreler\n\n\n[1] 35\n\n\nCode\nprint(length(ratings))   # Puanlar\n\n\n[1] 25\n\n\nCode\nprint(length(votes))     # Oy Sayıları\n\n\n[1] 25\n\n\n\n\nCode\nprint(titles)\n\n\n [1] \"1. Günesi Gördüm\"             \"2. Babam ve Oglum\"           \n [3] \"3. G.O.R.A.\"                  \"4. Barda\"                    \n [5] \"5. Uzak\"                      \"6. Kader\"                    \n [7] \"7. Eskiya\"                    \"8. Masumiyet\"                \n [9] \"9. Kabadayi\"                  \"10. Issiz Adam\"              \n[11] \"11. Uçurtmayi Vurmasinlar\"    \"12. Hababam Sinifi\"          \n[13] \"13. Yol\"                      \"14. Vavien\"                  \n[15] \"15. Kolpaçino\"                \"16. A.R.O.G\"                 \n[17] \"17. Nefes\"                    \"18. Agir Roman\"              \n[19] \"19. Üç Maymun\"                \"20. Yahsi Bati\"              \n[21] \"21. Gemide\"                   \"22. Iklimler\"                \n[23] \"23. Vizontele\"                \"24. Recep Ivedik\"            \n[25] \"25. Selvi Boylum Al Yazmalim\"\n\n\nCode\nprint(years)\n\n\n [1] 2009   NA   NA 2005   NA   NA 2004   NA   NA 2007   NA   NA 2002   NA   NA\n[16] 2006   NA   NA 1996   NA   NA 1997   NA   NA 2007   NA   NA 2008   NA   NA\n[31] 1989   NA 1975   NA 1982   NA   NA 2009   NA   NA 2009   NA   NA 2008   NA\n[46]   NA 2009   NA   NA 1997   NA   NA 2008   NA   NA 2009   NA   NA 1998   NA\n[61] 2006   NA   NA 2001   NA   NA 2008   NA   NA 1977   NA\n\n\nCode\nprint(durations)\n\n\n [1]   NA 2005   NA   NA 2007   NA   NA 2006   NA   NA 1997   NA   NA 2008   NA\n[16]   NA   NA   NA 2009   NA   NA 2008   NA   NA 1997   NA   NA 2009   NA   NA\n[31]   NA 2001   NA   NA 1977\n\n\nCode\nprint(ratings)\n\n\n [1] 6.6 8.2 8.0 7.0 7.5 7.7 8.1 8.1 7.8 6.8 8.3 9.2 8.0 7.5 6.5 7.4 8.0 7.6 7.3\n[20] 7.4 7.9 7.1 8.0 4.9 8.5\n\n\nCode\nprint(votes)\n\n\n [1] 11000 96000 68000 16000 24000 18000 73000 21000 25000 24000  7500 44000\n[13] 15000 14000 15000 46000 36000 12000 23000 39000 17000 15000 40000 30000\n[25] 17000\n\n\n\n\nCode\nprint(years)\n\n\n [1] 2009   NA   NA 2005   NA   NA 2004   NA   NA 2007   NA   NA 2002   NA   NA\n[16] 2006   NA   NA 1996   NA   NA 1997   NA   NA 2007   NA   NA 2008   NA   NA\n[31] 1989   NA 1975   NA 1982   NA   NA 2009   NA   NA 2009   NA   NA 2008   NA\n[46]   NA 2009   NA   NA 1997   NA   NA 2008   NA   NA 2009   NA   NA 1998   NA\n[61] 2006   NA   NA 2001   NA   NA 2008   NA   NA 1977   NA",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "PDF Download"
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\nTurkish Aerospace Industries, Candidate Engineer, November 2024 - May 2025"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n-"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts.\n\n\nI watched the video with Baykal Hafizoglu was the guest.\nData science and industrial engineering focus on merging analytical solutions with optimization models, like predicting daily inventory levels. There???s also an emphasis on various decision-making models and related software tools.\nPrototyping and user feedback are crucial, as a clean and user-friendly interface enhances project success. The prototyping phase creates a small version of the software before final development. Clear communication and user satisfaction are key to effective problem-solving.\nThese fields stress the importance of analysis and optimization???like reducing inventory costs through optimization. However, some analytical models might introduce new challenges. Visual aids and KPI comparisons help clarify problems and solutions. A well-designed user interface is essential for effective communication.\nMathematical modeling and programming skills are critical in these areas. Python is particularly valuable for practical problem-solving. Challenges in mathematical modeling might require more research, so learning specialized techniques is important.\nDiscussions often focus on demand forecasting and AI. Relying on a single forecast can be misleading, requiring deeper research into aspects like price elasticity. There’s an ongoing debate about AI’s role in future analytics and decision-making.\nQuestions:\n1. Give an specific daily life example of the Descriptive –&gt; Predictive –&gt; Prescriptive process.\nAnswer: You are applying for a loan. The bank checks whether you are reliable and if you will pay your debt on time. It calculates a score for this, and based on that score, your mortgage decision is determined. (Mortgage Application -&gt; Applicant???s Loan Score Estimation -&gt; Mortgage Decision)\n2. Which pairing could be wrong?\na) Descriptive Analytics &lt;- Data Mining\nb) Predictive Analytics &lt;- Simulation\nc) Diagnostic Analytics &lt;- Time Series Analysis\nd) Prescriptive Analytics &lt;- Optimization\ne) Predictive Analytics &lt;- Regression\nAnswer: c\n\n\n\nFirst, we are loading the dslabs library and pulling the polls_us_election_2016 dataset from it.\ninstall.packages(“dslabs”)\n\nlibrary(dslabs)\ndata(polls_us_election_2016)\n\nThe command head(polls_us_election_2016, 10) was used to display the first 10 rows of the dataset.\n\nhead(polls_us_election_2016, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  &lt;NA&gt;       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00               NA\n2          lv           38.03         35.69            5.46               NA\n3          lv           42.00         39.00            6.00               NA\n4          lv           45.00         41.00            5.00               NA\n5          rv           47.00         43.00            3.00               NA\n6          lv           48.00         44.00            3.00               NA\n7          lv           45.00         41.00            5.00               NA\n8          lv           44.00         40.00            6.00               NA\n9          lv           46.00         44.00            6.00               NA\n10         lv           41.20         42.70            7.10               NA\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221               NA\n2         43.34557      41.21439        5.175792               NA\n3         42.02638      38.81620        6.844734               NA\n4         45.65676      40.92004        6.069454               NA\n5         46.84089      42.33184        3.726098               NA\n6         49.02208      43.95631        3.057876               NA\n7         45.11649      40.92722        4.341786               NA\n8         43.58576      40.77325        5.365788               NA\n9         44.82594      41.59978        7.870127               NA\n10        42.92745      42.23545        6.316175               NA\n\n\nThe number of NA values in my dataset was displayed, and this count was printed.\n\ntotal_na &lt;- sum(is.na(polls_us_election_2016))\nprint(total_na)\n\n[1] 11604\n\n\nI assigned my name and birth year to a variable. To avoid altering my original dataset, I also assigned it to another variable. I determined the types of the columns using the sapply function. Since I planned to replace the factor columns with my name, I created a replace_na_in_factor function to prevent issues. I then iterated over each column using a for loop and replaced the NA values with my birth year and name. While doing this, I used if and if else statements to check whether the columns were numeric, character, or factor.\n\nbirth_year &lt;- 2002  # My birth year\nfirst_name &lt;- \"Gokhan\"  # My name\n\n# I Create a copy of the original dataset\nna_removed_data &lt;- polls_us_election_2016\n\n# Get column names and their types\ncol_types &lt;- sapply(na_removed_data, class)\n\n# Function to handle factors specifically\nreplace_na_in_factor &lt;- function(x, replacement) {\n  if (is.factor(x)) {\n    # Convert factor to character, replace NAs, then back to factor\n    levels_with_name &lt;- c(levels(x), replacement)\n    x &lt;- factor(replace(as.character(x), is.na(x), replacement),\n                levels = levels_with_name)\n  }\n  return(x)\n}\n\n# Loop through each column and replace NAs based on type\nfor (col in names(na_removed_data)) {\n  if (is.numeric(na_removed_data[[col]])) {\n    # Replace NAs in numeric columns with birth year\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- birth_year\n  } else if (is.character(na_removed_data[[col]])) {\n    # Replace NAs in character columns with first name\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- first_name\n  } else if (is.factor(na_removed_data[[col]])) {\n    # Handle factor columns\n    na_removed_data[[col]] &lt;- replace_na_in_factor(na_removed_data[[col]], first_name)\n  }\n}\n\nI took a look at my new dataset.\n\nhead(na_removed_data, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster  grade samplesize\n1                                    ABC News/Washington Post     A+       2220\n2                                     Google Consumer Surveys      B      26574\n3                                                       Ipsos     A-       2195\n4                                                      YouGov      B       3677\n5                                            Gravis Marketing     B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research      A       1295\n7                                     CBS News/New York Times     A-       1426\n8                                NBC News/Wall Street Journal     A-       1282\n9                                                    Zia Poll Gokhan       8439\n10                                                   IBD/TIPP     A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00             2002\n2          lv           38.03         35.69            5.46             2002\n3          lv           42.00         39.00            6.00             2002\n4          lv           45.00         41.00            5.00             2002\n5          rv           47.00         43.00            3.00             2002\n6          lv           48.00         44.00            3.00             2002\n7          lv           45.00         41.00            5.00             2002\n8          lv           44.00         40.00            6.00             2002\n9          lv           46.00         44.00            6.00             2002\n10         lv           41.20         42.70            7.10             2002\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221             2002\n2         43.34557      41.21439        5.175792             2002\n3         42.02638      38.81620        6.844734             2002\n4         45.65676      40.92004        6.069454             2002\n5         46.84089      42.33184        3.726098             2002\n6         49.02208      43.95631        3.057876             2002\n7         45.11649      40.92722        4.341786             2002\n8         43.58576      40.77325        5.365788             2002\n9         44.82594      41.59978        7.870127             2002\n10        42.92745      42.23545        6.316175             2002\n\n\nI wanted to check how many NA values there are in my new dataset.\n\nprint(new_total_number_na &lt;- sum(is.na(na_removed_data)))\n\n[1] 0",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g. Fall 2024] EMU430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\nThe most recent update to this page was made on October 21, 2024\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Loading…\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "(b)",
    "text": "(b)\nFirst, we are loading the dslabs library and pulling the polls_us_election_2016 dataset from it.\ninstall.packages(“dslabs”)\n\nlibrary(dslabs)\ndata(polls_us_election_2016)\n\nThe command head(polls_us_election_2016, 10) was used to display the first 10 rows of the dataset.\n\nhead(polls_us_election_2016, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  &lt;NA&gt;       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00               NA\n2          lv           38.03         35.69            5.46               NA\n3          lv           42.00         39.00            6.00               NA\n4          lv           45.00         41.00            5.00               NA\n5          rv           47.00         43.00            3.00               NA\n6          lv           48.00         44.00            3.00               NA\n7          lv           45.00         41.00            5.00               NA\n8          lv           44.00         40.00            6.00               NA\n9          lv           46.00         44.00            6.00               NA\n10         lv           41.20         42.70            7.10               NA\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221               NA\n2         43.34557      41.21439        5.175792               NA\n3         42.02638      38.81620        6.844734               NA\n4         45.65676      40.92004        6.069454               NA\n5         46.84089      42.33184        3.726098               NA\n6         49.02208      43.95631        3.057876               NA\n7         45.11649      40.92722        4.341786               NA\n8         43.58576      40.77325        5.365788               NA\n9         44.82594      41.59978        7.870127               NA\n10        42.92745      42.23545        6.316175               NA\n\n\nThe number of NA values in my dataset was displayed, and this count was printed.\n\ntotal_na &lt;- sum(is.na(polls_us_election_2016))\nprint(total_na)\n\n[1] 11604\n\n\nI assigned my name and birth year to a variable. To avoid altering my original dataset, I also assigned it to another variable. I determined the types of the columns using the sapply function. Since I planned to replace the factor columns with my name, I created a replace_na_in_factor function to prevent issues. I then iterated over each column using a for loop and replaced the NA values with my birth year and name. While doing this, I used if and if else statements to check whether the columns were numeric, character, or factor.\n\nbirth_year &lt;- 2002  # My birth year\nfirst_name &lt;- \"Gokhan\"  # My name\n\n# i created a copy of the original dataset\nna_removed_data &lt;- polls_us_election_2016\n\n# Get column names and their types\ncol_types &lt;- sapply(na_removed_data, class)\n\n# claude.ai helped me about that part\n# my prompt: \"I cannot change some factor NA values in my data with my name. How can I do this?\"\n\nreplace_na_in_factor &lt;- function(x, replacement) {\n  if (is.factor(x)) {\n    # Convert factor to character, replace NAs, then back to factor\n    levels_with_name &lt;- c(levels(x), replacement)\n    x &lt;- factor(replace(as.character(x), is.na(x), replacement),\n                levels = levels_with_name)\n  }\n  return(x)\n}\n\n# looped through each column and replaced NAs based on type.\nfor (col in names(na_removed_data)) {\n  if (is.numeric(na_removed_data[[col]])) {\n    # Replaced NAs in numeric columns with birth year\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- birth_year\n  } else if (is.character(na_removed_data[[col]])) {\n    # Replaced NAs in character columns with first name\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- first_name\n  } else if (is.factor(na_removed_data[[col]])) {\n    # factor columns\n    na_removed_data[[col]] &lt;- replace_na_in_factor(na_removed_data[[col]], first_name)\n  }\n}\n\nI took a look at my new dataset.\n\nhead(na_removed_data, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster  grade samplesize\n1                                    ABC News/Washington Post     A+       2220\n2                                     Google Consumer Surveys      B      26574\n3                                                       Ipsos     A-       2195\n4                                                      YouGov      B       3677\n5                                            Gravis Marketing     B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research      A       1295\n7                                     CBS News/New York Times     A-       1426\n8                                NBC News/Wall Street Journal     A-       1282\n9                                                    Zia Poll Gokhan       8439\n10                                                   IBD/TIPP     A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00             2002\n2          lv           38.03         35.69            5.46             2002\n3          lv           42.00         39.00            6.00             2002\n4          lv           45.00         41.00            5.00             2002\n5          rv           47.00         43.00            3.00             2002\n6          lv           48.00         44.00            3.00             2002\n7          lv           45.00         41.00            5.00             2002\n8          lv           44.00         40.00            6.00             2002\n9          lv           46.00         44.00            6.00             2002\n10         lv           41.20         42.70            7.10             2002\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221             2002\n2         43.34557      41.21439        5.175792             2002\n3         42.02638      38.81620        6.844734             2002\n4         45.65676      40.92004        6.069454             2002\n5         46.84089      42.33184        3.726098             2002\n6         49.02208      43.95631        3.057876             2002\n7         45.11649      40.92722        4.341786             2002\n8         43.58576      40.77325        5.365788             2002\n9         44.82594      41.59978        7.870127             2002\n10        42.92745      42.23545        6.316175             2002\n\n\nI wanted to check how many NA values there are in my new dataset.\n\nprint(new_total_number_na &lt;- sum(is.na(na_removed_data)))\n\n[1] 0",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "",
    "text": "I watched the video with Baykal Hafizoglu was the guest.\nData science and industrial engineering focus on merging analytical solutions with optimization models, like predicting daily inventory levels. There???s also an emphasis on various decision-making models and related software tools.\nPrototyping and user feedback are crucial, as a clean and user-friendly interface enhances project success. The prototyping phase creates a small version of the software before final development. Clear communication and user satisfaction are key to effective problem-solving.\nThese fields stress the importance of analysis and optimization???like reducing inventory costs through optimization. However, some analytical models might introduce new challenges. Visual aids and KPI comparisons help clarify problems and solutions. A well-designed user interface is essential for effective communication.\nMathematical modeling and programming skills are critical in these areas. Python is particularly valuable for practical problem-solving. Challenges in mathematical modeling might require more research, so learning specialized techniques is important.\nDiscussions often focus on demand forecasting and AI. Relying on a single forecast can be misleading, requiring deeper research into aspects like price elasticity. There’s an ongoing debate about AI’s role in future analytics and decision-making.\nQuestions:\n1. Give an specific daily life example of the Descriptive –&gt; Predictive –&gt; Prescriptive process.\nAnswer: You are applying for a loan. The bank checks whether you are reliable and if you will pay your debt on time. It calculates a score for this, and based on that score, your mortgage decision is determined. (Mortgage Application -&gt; Applicant???s Loan Score Estimation -&gt; Mortgage Decision)\n2. Which pairing could be wrong?\na) Descriptive Analytics &lt;- Data Mining\nb) Predictive Analytics &lt;- Simulation\nc) Diagnostic Analytics &lt;- Time Series Analysis\nd) Prescriptive Analytics &lt;- Optimization\ne) Predictive Analytics &lt;- Regression\nAnswer: c",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-2.html#using-the-filters-on-httpsm.imdb.comsearch-list-all-turkish-movies-with-more",
    "href": "assignments/assignment-2.html#using-the-filters-on-httpsm.imdb.comsearch-list-all-turkish-movies-with-more",
    "title": "Assignment 2",
    "section": "",
    "text": "than 2500 reviews, and save the URLs.\nhttps://m.imdb.com/search/title/?title_type=feature&num_votes=2500,&country_of_origin=TR\nmovies_2010_2023 &lt;- 2010-2023: https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\nmovies_before_2010 &lt;- - 2009: https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\n\n\nCode\nmovies_2010_2023 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\"\n\nmovies_before_2010 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"\n\nurls &lt;- c(movies_2010_2023, movies_before_2010)\n\n# Vektörü görüntüleme\nprint(urls)\n\n\n[1] \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\"\n[2] \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "assignments/assignment-2.html#start-web-scrapping-to-create-a-data-frame-with-columns-title-year-duration",
    "href": "assignments/assignment-2.html#start-web-scrapping-to-create-a-data-frame-with-columns-title-year-duration",
    "title": "Assignment 2",
    "section": "",
    "text": "Rating, Votes\nThe libraries we will need are:\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'ggplot2' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.2\n\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.2\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'stringr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(rvest)\n\n\nWarning: package 'rvest' was built under R version 4.4.2\n\n\n\nAttaching package: 'rvest'\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n\nCode\nlibrary(stringr)\n\n\n\n\nCode\n# Veri çekmek için boş bir liste oluşturun\ndata_list &lt;- list()\n\n# Her URL için veri çekimi\nfor (url in urls) {\n  page &lt;- read_html(url)\n  \n  # Başlıklar\n  titles &lt;- page |&gt;\n    html_nodes('.ipc-title__text') |&gt; \n    html_text() |&gt;\n  tail(-1) |&gt;  # İlk öğeyi kaldır\n  head(-1)\n  \n  # Yıllar ve Süreler\n  metadata &lt;- page |&gt;\n    html_nodes('.sc-300a8231-7.eaXxft.dli-title-metadata-item') |&gt; \n    html_text()\n  \n  years &lt;- metadata |&gt; \n  str_extract(\"^\\\\d{4}$\") |&gt;  # Sadece 4 basamaklı yıl bilgilerini seç\n  as.numeric()  \n  \n  durations &lt;- metadata[seq(2, length(metadata), by = 2)] |&gt; \n    str_replace(\" min\", \"\") |&gt; \n    as.numeric()\n  \n  # Oyların ham verisini kontrol et\nraw_votes &lt;- page |&gt;\n  html_nodes('.ipc-rating-star--voteCount') |&gt; \n  html_text()\n  \n  # Puanlar\n  ratings &lt;- page |&gt;\n    html_nodes('.ipc-rating-star--rating') |&gt; \n    html_text() |&gt; \n    as.numeric()\n  \n  # Oy Sayıları\n  votes &lt;- raw_votes |&gt;\n  str_trim() |&gt;                            # Başındaki ve sonundaki boşlukları kaldır\n  str_replace_all('\"', \"\") |&gt;              # Çift tırnakları kaldır\n  str_replace_all(\"K\", \"e3\") |&gt;            # \"K\"yi bilimsel gösterimle 1000 olarak değiştir\n  str_replace_all(\"k\", \"e3\") |&gt;            # \"k\" için de aynı işlemi yap\n  parse_number()                           # Metni sayıya dönüştür\n\n\n  \n  # Çekilen verileri listeye ekleyin\n  data_list[[url]] &lt;- list(\n    titles = titles,\n    years = years,\n    durations = durations,\n    ratings = ratings,\n    votes = votes\n  )\n}\n\n\nWarning: Zorlamadan dolayı ortaya çıkan NAs\nWarning: Zorlamadan dolayı ortaya çıkan NAs\n\n\nCode\n# Sonuçları kontrol edin\nhead(data_list[[urls[1]]]$votes)\n\n\n[1] 16000 58000 10000  4500 57000 45000\n\n\n\n\nCode\nprint(metadata)\n\n\n [1] \"2009\"      \"2h\"        \"G\"         \"2005\"      \"1h 48m\"    \"G\"        \n [7] \"2004\"      \"2h 7m\"     \"18+\"       \"2007\"      \"1h 32m\"    \"13+\"      \n[13] \"2002\"      \"1h 50m\"    \"18+\"       \"2006\"      \"1h 43m\"    \"18+\"      \n[19] \"1996\"      \"2h 8m\"     \"7+\"        \"1997\"      \"1h 50m\"    \"13+\"      \n[25] \"2007\"      \"2h 20m\"    \"7+\"        \"2008\"      \"1h 53m\"    \"13+\"      \n[31] \"1989\"      \"1h 25m\"    \"1975\"      \"1h 25m\"    \"1982\"      \"1h 47m\"   \n[37] \"PG\"        \"2009\"      \"1h 40m\"    \"7+\"        \"2009\"      \"1h 38m\"   \n[43] \"13+\"       \"2008\"      \"2h 7m\"     \"13+\"       \"2009\"      \"2h 8m\"    \n[49] \"13+\"       \"1997\"      \"2h\"        \"13+\"       \"2008\"      \"1h 49m\"   \n[55] \"Not Rated\" \"2009\"      \"1h 52m\"    \"7+\"        \"1998\"      \"1h 42m\"   \n[61] \"2006\"      \"1h 37m\"    \"Unrated\"   \"2001\"      \"1h 50m\"    \"16+\"      \n[67] \"2008\"      \"1h 30m\"    \"13+\"       \"1977\"      \"1h 30m\"   \n\n\n\n\nCode\nprint(length(titles))    # Başlıklar\n\n\n[1] 25\n\n\nCode\nprint(length(years))     # Yıllar\n\n\n[1] 71\n\n\nCode\nprint(length(durations)) # Süreler\n\n\n[1] 35\n\n\nCode\nprint(length(ratings))   # Puanlar\n\n\n[1] 25\n\n\nCode\nprint(length(votes))     # Oy Sayıları\n\n\n[1] 25\n\n\n\n\nCode\nprint(titles)\n\n\n [1] \"1. Günesi Gördüm\"             \"2. Babam ve Oglum\"           \n [3] \"3. G.O.R.A.\"                  \"4. Barda\"                    \n [5] \"5. Uzak\"                      \"6. Kader\"                    \n [7] \"7. Eskiya\"                    \"8. Masumiyet\"                \n [9] \"9. Kabadayi\"                  \"10. Issiz Adam\"              \n[11] \"11. Uçurtmayi Vurmasinlar\"    \"12. Hababam Sinifi\"          \n[13] \"13. Yol\"                      \"14. Vavien\"                  \n[15] \"15. Kolpaçino\"                \"16. A.R.O.G\"                 \n[17] \"17. Nefes\"                    \"18. Agir Roman\"              \n[19] \"19. Üç Maymun\"                \"20. Yahsi Bati\"              \n[21] \"21. Gemide\"                   \"22. Iklimler\"                \n[23] \"23. Vizontele\"                \"24. Recep Ivedik\"            \n[25] \"25. Selvi Boylum Al Yazmalim\"\n\n\nCode\nprint(years)\n\n\n [1] 2009   NA   NA 2005   NA   NA 2004   NA   NA 2007   NA   NA 2002   NA   NA\n[16] 2006   NA   NA 1996   NA   NA 1997   NA   NA 2007   NA   NA 2008   NA   NA\n[31] 1989   NA 1975   NA 1982   NA   NA 2009   NA   NA 2009   NA   NA 2008   NA\n[46]   NA 2009   NA   NA 1997   NA   NA 2008   NA   NA 2009   NA   NA 1998   NA\n[61] 2006   NA   NA 2001   NA   NA 2008   NA   NA 1977   NA\n\n\nCode\nprint(durations)\n\n\n [1]   NA 2005   NA   NA 2007   NA   NA 2006   NA   NA 1997   NA   NA 2008   NA\n[16]   NA   NA   NA 2009   NA   NA 2008   NA   NA 1997   NA   NA 2009   NA   NA\n[31]   NA 2001   NA   NA 1977\n\n\nCode\nprint(ratings)\n\n\n [1] 6.6 8.2 8.0 7.0 7.5 7.7 8.1 8.1 7.8 6.8 8.3 9.2 8.0 7.5 6.5 7.4 8.0 7.6 7.3\n[20] 7.4 7.9 7.1 8.0 4.9 8.5\n\n\nCode\nprint(votes)\n\n\n [1] 11000 96000 68000 16000 24000 18000 73000 21000 25000 24000  7500 44000\n[13] 15000 14000 15000 46000 36000 12000 23000 39000 17000 15000 40000 30000\n[25] 17000\n\n\n\n\nCode\nprint(years)\n\n\n [1] 2009   NA   NA 2005   NA   NA 2004   NA   NA 2007   NA   NA 2002   NA   NA\n[16] 2006   NA   NA 1996   NA   NA 1997   NA   NA 2007   NA   NA 2008   NA   NA\n[31] 1989   NA 1975   NA 1982   NA   NA 2009   NA   NA 2009   NA   NA 2008   NA\n[46]   NA 2009   NA   NA 1997   NA   NA 2008   NA   NA 2009   NA   NA 1998   NA\n[61] 2006   NA   NA 2001   NA   NA 2008   NA   NA 1977   NA",
    "crumbs": [
      "Assignment 2"
    ]
  }
]