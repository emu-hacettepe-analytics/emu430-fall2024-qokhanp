[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Our Course Project",
    "section": "",
    "text": "I’m honored to be a member of the NRG project team.\nBelow, you’ll find a brief summary of our project. To access a detailed project description, please go to EMU430_project_team_NRG.\nSummary\nOur project explores the role of electric vehicles (EVs) in reducing CO2 emissions and assesses their integration within Türkiye. EVs are recognized for their environmental advantages, especially their capacity to lower transportation-related carbon emissions. This study highlights that although adopting EVs can substantially mitigate emissions, its overall success is influenced by factors like population density and the shift toward renewable energy in electricity production.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello, i am Gokhan Polat,\nan Industrial Engineering student with a passion for data analytics, sustainable development, and technology-driven solutions. On this website, i will be sharing my latest projects, insights into data analysis, and much more.\nFeel free to connect and follow along!\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "than 2500 reviews, and save the URLs.\nhttps://m.imdb.com/search/title/?title_type=feature&num_votes=2500,&country_of_origin=TR\nmovies_2010_2023 &lt;- 2010-2023: https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\nmovies_before_2010 &lt;- - 2009: https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\n\n\n[1] \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\"\n[2] \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"          \n\n\n\n\n\nThe libraries we will need are:\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(stringi)\n\n\n\n\nCode\n# Tüm veriler için boş bir liste oluştur\nall_movies &lt;- list()\n\nfor (url in urls) {\n  data_html &lt;- read_html(url)\n  \n# Başlıkları çekme ve temizleme\ntitles &lt;- data_html |&gt; \n  html_nodes('.ipc-title__text') |&gt; \n  html_text() |&gt; \n  tail(-1)\ntitles &lt;- head(titles, -1)\n\n\n# Kodlamayı ve boşlukları düzelt\ncleaned_titles &lt;- sapply(titles, simplify_text)\n\n# Benzersiz başlıkları seçmek ve bozuk olanları temizlemek\ncleaned_titles &lt;- unique(cleaned_titles)  # Tekrarlayan başlıkları kaldır\ncleaned_titles &lt;- cleaned_titles[!grepl(\"\\\\?\\\\u\", cleaned_titles)]  # Bozuk başlıkları kaldır\n  \n  # Yılları çekme\n  years &lt;- data_html |&gt; \n    html_nodes('.sc-300a8231-7.eaXxft.dli-title-metadata-item:nth-child(1)') |&gt; \n    html_text() |&gt; \n    str_extract(\"\\\\d{4}\") |&gt; \n    as.numeric()\n  \ndurations &lt;- data_html |&gt; \n  html_nodes('.sc-300a8231-7.eaXxft.dli-title-metadata-item:nth-child(2)') |&gt; \n  html_text()\n\n# Süreleri dakikaya çevirme\nconvert_duration_to_minutes &lt;- function(duration) {\n  # Saat ve dakika formatını kontrol et\n  if (grepl(\"^\\\\d+h$\", duration)) {\n    # Sadece saat varsa (örn: \"2h\")\n    hours &lt;- as.numeric(gsub(\"h$\", \"\", duration))\n    return(hours * 60)\n  } else {\n    # Saat ve dakika varsa (örn: \"2h 7m\")\n    matches &lt;- str_match(duration, \"(\\\\d+)h (\\\\d+)m\")\n    hours &lt;- as.numeric(matches[, 2])\n    minutes &lt;- as.numeric(matches[, 3])\n    return(hours * 60 + minutes)\n  }\n}\n\n# Tüm süreleri dakikaya çevir\ndurations_in_minutes &lt;- sapply(durations, convert_duration_to_minutes)\n  \n  # Puanları çekme\n  ratings &lt;- data_html |&gt; \n    html_nodes('.ipc-rating-star--rating') |&gt; \n    html_text() |&gt; \n    as.numeric()\n  \n  # Oy sayısını çekme ve temizleme\n  votes_raw &lt;- data_html |&gt; \n    html_nodes('.ipc-rating-star--voteCount') |&gt; \n    html_text()\n  \n  votes_clean &lt;- sapply(votes_raw, clean_vote)\n  \n  # Veri çerçevesi oluşturma\n  movies &lt;- data.frame(\n    Title = cleaned_titles,\n    Year = years,\n    Duration = durations_in_minutes,\n    Rating = ratings,\n    Votes = votes_clean\n  )\n  \n  # Tüm filmleri birleştir\n  all_movies &lt;- append(all_movies, list(movies))\n}\n\n# Sonuçları birleştir\nfinal_movies &lt;- bind_rows(all_movies)\n\n# Veri çerçevesini görüntüleme\nprint(movies)\n\n\n                       Title Year Duration Rating Votes\n1          1. Babam ve Oglum 2005      108    8.2 96000\n2           2. Gunesi Gordum 2009      120    6.6 11000\n3                3. G.O.R.A. 2004      127    8.0 69000\n4                    4. Uzak 2002      110    7.5 24000\n5               5. Masumiyet 1997      110    8.1 21000\n6                  6. Eskiya 1996      128    8.1 73000\n7                   7. Kader 2006      103    7.7 18000\n8          8. Hababam Sinifi 1975       85    9.2 44000\n9              9. Issiz Adam 2008      113    6.8 24000\n10                 10. Barda 2007       92    7.0 16000\n11 11. Ucurtmayi Vurmasinlar 1989       85    8.2 76000\n12                 12. D@bbe 2006      110    4.3 49000\n13                   13. Yol 1982      107    7.9 15000\n14                14. Vavien 2009      100    7.5 14000\n15  15. Kurtlar Vadisi: Irak 2006      122    5.7 19000\n16                 16. Nefes 2009      128    8.0 36000\n17            17. Agir Roman 1997      120    7.6 12000\n18             18. Vizontele 2001      110    8.0 40000\n19             19. Uc Maymun 2008      109    7.3 23000\n20         20. Sevmek Zamani 1965       86    7.9 79000\n21          21. Recep Ivedik 2008       90    4.9 30000\n22                22. Gemide 1998      102    7.9 17000\n23               23. A.R.O.G 2008      127    7.4 47000\n24            24. Yahsi Bati 2009      112    7.4 39000\n25                25. Itiraf 2001      100    7.0 43000",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "PDF Download"
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\nTurkish Aerospace Industries, Candidate Engineer, November 2024 - May 2025"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n-"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts.\n\n\nI watched the video with Baykal Hafizoglu was the guest.\nData science and industrial engineering focus on merging analytical solutions with optimization models, like predicting daily inventory levels. There???s also an emphasis on various decision-making models and related software tools.\nPrototyping and user feedback are crucial, as a clean and user-friendly interface enhances project success. The prototyping phase creates a small version of the software before final development. Clear communication and user satisfaction are key to effective problem-solving.\nThese fields stress the importance of analysis and optimization???like reducing inventory costs through optimization. However, some analytical models might introduce new challenges. Visual aids and KPI comparisons help clarify problems and solutions. A well-designed user interface is essential for effective communication.\nMathematical modeling and programming skills are critical in these areas. Python is particularly valuable for practical problem-solving. Challenges in mathematical modeling might require more research, so learning specialized techniques is important.\nDiscussions often focus on demand forecasting and AI. Relying on a single forecast can be misleading, requiring deeper research into aspects like price elasticity. There’s an ongoing debate about AI’s role in future analytics and decision-making.\nQuestions:\n1. Give an specific daily life example of the Descriptive –&gt; Predictive –&gt; Prescriptive process.\nAnswer: You are applying for a loan. The bank checks whether you are reliable and if you will pay your debt on time. It calculates a score for this, and based on that score, your mortgage decision is determined. (Mortgage Application -&gt; Applicant???s Loan Score Estimation -&gt; Mortgage Decision)\n2. Which pairing could be wrong?\na) Descriptive Analytics &lt;- Data Mining\nb) Predictive Analytics &lt;- Simulation\nc) Diagnostic Analytics &lt;- Time Series Analysis\nd) Prescriptive Analytics &lt;- Optimization\ne) Predictive Analytics &lt;- Regression\nAnswer: c\n\n\n\nFirst, we are loading the dslabs library and pulling the polls_us_election_2016 dataset from it.\ninstall.packages(“dslabs”)\n\nlibrary(dslabs)\ndata(polls_us_election_2016)\n\nThe command head(polls_us_election_2016, 10) was used to display the first 10 rows of the dataset.\n\nhead(polls_us_election_2016, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  &lt;NA&gt;       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00               NA\n2          lv           38.03         35.69            5.46               NA\n3          lv           42.00         39.00            6.00               NA\n4          lv           45.00         41.00            5.00               NA\n5          rv           47.00         43.00            3.00               NA\n6          lv           48.00         44.00            3.00               NA\n7          lv           45.00         41.00            5.00               NA\n8          lv           44.00         40.00            6.00               NA\n9          lv           46.00         44.00            6.00               NA\n10         lv           41.20         42.70            7.10               NA\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221               NA\n2         43.34557      41.21439        5.175792               NA\n3         42.02638      38.81620        6.844734               NA\n4         45.65676      40.92004        6.069454               NA\n5         46.84089      42.33184        3.726098               NA\n6         49.02208      43.95631        3.057876               NA\n7         45.11649      40.92722        4.341786               NA\n8         43.58576      40.77325        5.365788               NA\n9         44.82594      41.59978        7.870127               NA\n10        42.92745      42.23545        6.316175               NA\n\n\nThe number of NA values in my dataset was displayed, and this count was printed.\n\ntotal_na &lt;- sum(is.na(polls_us_election_2016))\nprint(total_na)\n\n[1] 11604\n\n\nI assigned my name and birth year to a variable. To avoid altering my original dataset, I also assigned it to another variable. I determined the types of the columns using the sapply function. Since I planned to replace the factor columns with my name, I created a replace_na_in_factor function to prevent issues. I then iterated over each column using a for loop and replaced the NA values with my birth year and name. While doing this, I used if and if else statements to check whether the columns were numeric, character, or factor.\n\nbirth_year &lt;- 2002  # My birth year\nfirst_name &lt;- \"Gokhan\"  # My name\n\n# I Create a copy of the original dataset\nna_removed_data &lt;- polls_us_election_2016\n\n# Get column names and their types\ncol_types &lt;- sapply(na_removed_data, class)\n\n# Function to handle factors specifically\nreplace_na_in_factor &lt;- function(x, replacement) {\n  if (is.factor(x)) {\n    # Convert factor to character, replace NAs, then back to factor\n    levels_with_name &lt;- c(levels(x), replacement)\n    x &lt;- factor(replace(as.character(x), is.na(x), replacement),\n                levels = levels_with_name)\n  }\n  return(x)\n}\n\n# Loop through each column and replace NAs based on type\nfor (col in names(na_removed_data)) {\n  if (is.numeric(na_removed_data[[col]])) {\n    # Replace NAs in numeric columns with birth year\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- birth_year\n  } else if (is.character(na_removed_data[[col]])) {\n    # Replace NAs in character columns with first name\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- first_name\n  } else if (is.factor(na_removed_data[[col]])) {\n    # Handle factor columns\n    na_removed_data[[col]] &lt;- replace_na_in_factor(na_removed_data[[col]], first_name)\n  }\n}\n\nI took a look at my new dataset.\n\nhead(na_removed_data, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster  grade samplesize\n1                                    ABC News/Washington Post     A+       2220\n2                                     Google Consumer Surveys      B      26574\n3                                                       Ipsos     A-       2195\n4                                                      YouGov      B       3677\n5                                            Gravis Marketing     B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research      A       1295\n7                                     CBS News/New York Times     A-       1426\n8                                NBC News/Wall Street Journal     A-       1282\n9                                                    Zia Poll Gokhan       8439\n10                                                   IBD/TIPP     A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00             2002\n2          lv           38.03         35.69            5.46             2002\n3          lv           42.00         39.00            6.00             2002\n4          lv           45.00         41.00            5.00             2002\n5          rv           47.00         43.00            3.00             2002\n6          lv           48.00         44.00            3.00             2002\n7          lv           45.00         41.00            5.00             2002\n8          lv           44.00         40.00            6.00             2002\n9          lv           46.00         44.00            6.00             2002\n10         lv           41.20         42.70            7.10             2002\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221             2002\n2         43.34557      41.21439        5.175792             2002\n3         42.02638      38.81620        6.844734             2002\n4         45.65676      40.92004        6.069454             2002\n5         46.84089      42.33184        3.726098             2002\n6         49.02208      43.95631        3.057876             2002\n7         45.11649      40.92722        4.341786             2002\n8         43.58576      40.77325        5.365788             2002\n9         44.82594      41.59978        7.870127             2002\n10        42.92745      42.23545        6.316175             2002\n\n\nI wanted to check how many NA values there are in my new dataset.\n\nprint(new_total_number_na &lt;- sum(is.na(na_removed_data)))\n\n[1] 0",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g. Fall 2024] EMU430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\nThe most recent update to this page was made on October 21, 2024\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Loading…\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "(b)",
    "text": "(b)\nFirst, we are loading the dslabs library and pulling the polls_us_election_2016 dataset from it.\ninstall.packages(“dslabs”)\n\nlibrary(dslabs)\ndata(polls_us_election_2016)\n\nThe command head(polls_us_election_2016, 10) was used to display the first 10 rows of the dataset.\n\nhead(polls_us_election_2016, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  &lt;NA&gt;       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00               NA\n2          lv           38.03         35.69            5.46               NA\n3          lv           42.00         39.00            6.00               NA\n4          lv           45.00         41.00            5.00               NA\n5          rv           47.00         43.00            3.00               NA\n6          lv           48.00         44.00            3.00               NA\n7          lv           45.00         41.00            5.00               NA\n8          lv           44.00         40.00            6.00               NA\n9          lv           46.00         44.00            6.00               NA\n10         lv           41.20         42.70            7.10               NA\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221               NA\n2         43.34557      41.21439        5.175792               NA\n3         42.02638      38.81620        6.844734               NA\n4         45.65676      40.92004        6.069454               NA\n5         46.84089      42.33184        3.726098               NA\n6         49.02208      43.95631        3.057876               NA\n7         45.11649      40.92722        4.341786               NA\n8         43.58576      40.77325        5.365788               NA\n9         44.82594      41.59978        7.870127               NA\n10        42.92745      42.23545        6.316175               NA\n\n\nThe number of NA values in my dataset was displayed, and this count was printed.\n\ntotal_na &lt;- sum(is.na(polls_us_election_2016))\nprint(total_na)\n\n[1] 11604\n\n\nI assigned my name and birth year to a variable. To avoid altering my original dataset, I also assigned it to another variable. I determined the types of the columns using the sapply function. Since I planned to replace the factor columns with my name, I created a replace_na_in_factor function to prevent issues. I then iterated over each column using a for loop and replaced the NA values with my birth year and name. While doing this, I used if and if else statements to check whether the columns were numeric, character, or factor.\n\nbirth_year &lt;- 2002  # My birth year\nfirst_name &lt;- \"Gokhan\"  # My name\n\n# i created a copy of the original dataset\nna_removed_data &lt;- polls_us_election_2016\n\n# Get column names and their types\ncol_types &lt;- sapply(na_removed_data, class)\n\n# claude.ai helped me about that part\n# my prompt: \"I cannot change some factor NA values in my data with my name. How can I do this?\"\n\nreplace_na_in_factor &lt;- function(x, replacement) {\n  if (is.factor(x)) {\n    # Convert factor to character, replace NAs, then back to factor\n    levels_with_name &lt;- c(levels(x), replacement)\n    x &lt;- factor(replace(as.character(x), is.na(x), replacement),\n                levels = levels_with_name)\n  }\n  return(x)\n}\n\n# looped through each column and replaced NAs based on type.\nfor (col in names(na_removed_data)) {\n  if (is.numeric(na_removed_data[[col]])) {\n    # Replaced NAs in numeric columns with birth year\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- birth_year\n  } else if (is.character(na_removed_data[[col]])) {\n    # Replaced NAs in character columns with first name\n    na_removed_data[[col]][is.na(na_removed_data[[col]])] &lt;- first_name\n  } else if (is.factor(na_removed_data[[col]])) {\n    # factor columns\n    na_removed_data[[col]] &lt;- replace_na_in_factor(na_removed_data[[col]], first_name)\n  }\n}\n\nI took a look at my new dataset.\n\nhead(na_removed_data, 10)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster  grade samplesize\n1                                    ABC News/Washington Post     A+       2220\n2                                     Google Consumer Surveys      B      26574\n3                                                       Ipsos     A-       2195\n4                                                      YouGov      B       3677\n5                                            Gravis Marketing     B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research      A       1295\n7                                     CBS News/New York Times     A-       1426\n8                                NBC News/Wall Street Journal     A-       1282\n9                                                    Zia Poll Gokhan       8439\n10                                                   IBD/TIPP     A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00             2002\n2          lv           38.03         35.69            5.46             2002\n3          lv           42.00         39.00            6.00             2002\n4          lv           45.00         41.00            5.00             2002\n5          rv           47.00         43.00            3.00             2002\n6          lv           48.00         44.00            3.00             2002\n7          lv           45.00         41.00            5.00             2002\n8          lv           44.00         40.00            6.00             2002\n9          lv           46.00         44.00            6.00             2002\n10         lv           41.20         42.70            7.10             2002\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221             2002\n2         43.34557      41.21439        5.175792             2002\n3         42.02638      38.81620        6.844734             2002\n4         45.65676      40.92004        6.069454             2002\n5         46.84089      42.33184        3.726098             2002\n6         49.02208      43.95631        3.057876             2002\n7         45.11649      40.92722        4.341786             2002\n8         43.58576      40.77325        5.365788             2002\n9         44.82594      41.59978        7.870127             2002\n10        42.92745      42.23545        6.316175             2002\n\n\nI wanted to check how many NA values there are in my new dataset.\n\nprint(new_total_number_na &lt;- sum(is.na(na_removed_data)))\n\n[1] 0",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "",
    "text": "I watched the video with Baykal Hafizoglu was the guest.\nData science and industrial engineering focus on merging analytical solutions with optimization models, like predicting daily inventory levels. There???s also an emphasis on various decision-making models and related software tools.\nPrototyping and user feedback are crucial, as a clean and user-friendly interface enhances project success. The prototyping phase creates a small version of the software before final development. Clear communication and user satisfaction are key to effective problem-solving.\nThese fields stress the importance of analysis and optimization???like reducing inventory costs through optimization. However, some analytical models might introduce new challenges. Visual aids and KPI comparisons help clarify problems and solutions. A well-designed user interface is essential for effective communication.\nMathematical modeling and programming skills are critical in these areas. Python is particularly valuable for practical problem-solving. Challenges in mathematical modeling might require more research, so learning specialized techniques is important.\nDiscussions often focus on demand forecasting and AI. Relying on a single forecast can be misleading, requiring deeper research into aspects like price elasticity. There’s an ongoing debate about AI’s role in future analytics and decision-making.\nQuestions:\n1. Give an specific daily life example of the Descriptive –&gt; Predictive –&gt; Prescriptive process.\nAnswer: You are applying for a loan. The bank checks whether you are reliable and if you will pay your debt on time. It calculates a score for this, and based on that score, your mortgage decision is determined. (Mortgage Application -&gt; Applicant???s Loan Score Estimation -&gt; Mortgage Decision)\n2. Which pairing could be wrong?\na) Descriptive Analytics &lt;- Data Mining\nb) Predictive Analytics &lt;- Simulation\nc) Diagnostic Analytics &lt;- Time Series Analysis\nd) Prescriptive Analytics &lt;- Optimization\ne) Predictive Analytics &lt;- Regression\nAnswer: c",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-2.html#using-the-filters-on-httpsm.imdb.comsearch-list-all-turkish-movies-with-more",
    "href": "assignments/assignment-2.html#using-the-filters-on-httpsm.imdb.comsearch-list-all-turkish-movies-with-more",
    "title": "Assignment 2",
    "section": "",
    "text": "than 2500 reviews, and save the URLs.\nhttps://m.imdb.com/search/title/?title_type=feature&num_votes=2500,&country_of_origin=TR\nmovies_2010_2023 &lt;- 2010-2023: https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\nmovies_before_2010 &lt;- - 2009: https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\n\n\n[1] \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-30&num_votes=2500,&country_of_origin=TR&count=250\"\n[2] \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "assignments/assignment-2.html#start-web-scrapping-to-create-a-data-frame-with-columns-title-year-duration",
    "href": "assignments/assignment-2.html#start-web-scrapping-to-create-a-data-frame-with-columns-title-year-duration",
    "title": "Assignment 2",
    "section": "",
    "text": "The libraries we will need are:\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(stringi)\n\n\n\n\nCode\n# Tüm veriler için boş bir liste oluştur\nall_movies &lt;- list()\n\nfor (url in urls) {\n  data_html &lt;- read_html(url)\n  \n# Başlıkları çekme ve temizleme\ntitles &lt;- data_html |&gt; \n  html_nodes('.ipc-title__text') |&gt; \n  html_text() |&gt; \n  tail(-1)\ntitles &lt;- head(titles, -1)\n\n\n# Kodlamayı ve boşlukları düzelt\ncleaned_titles &lt;- sapply(titles, simplify_text)\n\n# Benzersiz başlıkları seçmek ve bozuk olanları temizlemek\ncleaned_titles &lt;- unique(cleaned_titles)  # Tekrarlayan başlıkları kaldır\ncleaned_titles &lt;- cleaned_titles[!grepl(\"\\\\?\\\\u\", cleaned_titles)]  # Bozuk başlıkları kaldır\n  \n  # Yılları çekme\n  years &lt;- data_html |&gt; \n    html_nodes('.sc-300a8231-7.eaXxft.dli-title-metadata-item:nth-child(1)') |&gt; \n    html_text() |&gt; \n    str_extract(\"\\\\d{4}\") |&gt; \n    as.numeric()\n  \ndurations &lt;- data_html |&gt; \n  html_nodes('.sc-300a8231-7.eaXxft.dli-title-metadata-item:nth-child(2)') |&gt; \n  html_text()\n\n# Süreleri dakikaya çevirme\nconvert_duration_to_minutes &lt;- function(duration) {\n  # Saat ve dakika formatını kontrol et\n  if (grepl(\"^\\\\d+h$\", duration)) {\n    # Sadece saat varsa (örn: \"2h\")\n    hours &lt;- as.numeric(gsub(\"h$\", \"\", duration))\n    return(hours * 60)\n  } else {\n    # Saat ve dakika varsa (örn: \"2h 7m\")\n    matches &lt;- str_match(duration, \"(\\\\d+)h (\\\\d+)m\")\n    hours &lt;- as.numeric(matches[, 2])\n    minutes &lt;- as.numeric(matches[, 3])\n    return(hours * 60 + minutes)\n  }\n}\n\n# Tüm süreleri dakikaya çevir\ndurations_in_minutes &lt;- sapply(durations, convert_duration_to_minutes)\n  \n  # Puanları çekme\n  ratings &lt;- data_html |&gt; \n    html_nodes('.ipc-rating-star--rating') |&gt; \n    html_text() |&gt; \n    as.numeric()\n  \n  # Oy sayısını çekme ve temizleme\n  votes_raw &lt;- data_html |&gt; \n    html_nodes('.ipc-rating-star--voteCount') |&gt; \n    html_text()\n  \n  votes_clean &lt;- sapply(votes_raw, clean_vote)\n  \n  # Veri çerçevesi oluşturma\n  movies &lt;- data.frame(\n    Title = cleaned_titles,\n    Year = years,\n    Duration = durations_in_minutes,\n    Rating = ratings,\n    Votes = votes_clean\n  )\n  \n  # Tüm filmleri birleştir\n  all_movies &lt;- append(all_movies, list(movies))\n}\n\n# Sonuçları birleştir\nfinal_movies &lt;- bind_rows(all_movies)\n\n# Veri çerçevesini görüntüleme\nprint(movies)\n\n\n                       Title Year Duration Rating Votes\n1          1. Babam ve Oglum 2005      108    8.2 96000\n2           2. Gunesi Gordum 2009      120    6.6 11000\n3                3. G.O.R.A. 2004      127    8.0 69000\n4                    4. Uzak 2002      110    7.5 24000\n5               5. Masumiyet 1997      110    8.1 21000\n6                  6. Eskiya 1996      128    8.1 73000\n7                   7. Kader 2006      103    7.7 18000\n8          8. Hababam Sinifi 1975       85    9.2 44000\n9              9. Issiz Adam 2008      113    6.8 24000\n10                 10. Barda 2007       92    7.0 16000\n11 11. Ucurtmayi Vurmasinlar 1989       85    8.2 76000\n12                 12. D@bbe 2006      110    4.3 49000\n13                   13. Yol 1982      107    7.9 15000\n14                14. Vavien 2009      100    7.5 14000\n15  15. Kurtlar Vadisi: Irak 2006      122    5.7 19000\n16                 16. Nefes 2009      128    8.0 36000\n17            17. Agir Roman 1997      120    7.6 12000\n18             18. Vizontele 2001      110    8.0 40000\n19             19. Uc Maymun 2008      109    7.3 23000\n20         20. Sevmek Zamani 1965       86    7.9 79000\n21          21. Recep Ivedik 2008       90    4.9 30000\n22                22. Gemide 1998      102    7.9 17000\n23               23. A.R.O.G 2008      127    7.4 47000\n24            24. Yahsi Bati 2009      112    7.4 39000\n25                25. Itiraf 2001      100    7.0 43000",
    "crumbs": [
      "Assignment 2"
    ]
  }
]